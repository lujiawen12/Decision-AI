{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8faaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1a72e",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886dbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy提供多维度的数组对象，以及针对数组对象的各种快速操作，例如排序、变换、选择等\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa2bd6",
   "metadata": {},
   "source": [
    "## 基本操作 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c16dd8",
   "metadata": {},
   "source": [
    "### 数组创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba5034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一维、二维和三维数组\n",
    "arr_1_d = np.asarray([1])\n",
    "print(\"arr_1_d=\", arr_1_d)\n",
    "print(arr_1_d[0])\n",
    "\n",
    "arr_2_d = np.asarray([[1, 2], [3, 4]])\n",
    "print(\"arr_2_d=\", arr_2_d)\n",
    "print(arr_2_d[0][0])\n",
    "\n",
    "arr_3_d = np.asanyarray([[[1], [2]], [[3], [4]], [[5], [6]]])\n",
    "print(\"arr_3_d=\", arr_3_d)\n",
    "print(arr_3_d[0][0][0])\n",
    "\n",
    "# 0、1数组\n",
    "arr_ones = np.ones(shape=(2,3), dtype='float')\n",
    "print(\"arr_ones=\", arr_ones)\n",
    "\n",
    "arr_zeros = np.zeros(shape=(1,2,3), dtype='int')\n",
    "print(\"arr_zeros=\", arr_zeros)\n",
    "\n",
    "# np.array() 属于深拷贝，np.asarray() 则是浅拷贝\n",
    "copy_arr = np.array(arr_1_d)\n",
    "copy_arr[0] = 100\n",
    "print(copy_arr[0])\n",
    "print(arr_1_d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b14f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其他数组创建方式\n",
    "arr_arange = np.arange(0, 10, 2)\n",
    "print(arr_arange)\n",
    "\n",
    "arr_linspace = np.linspace(start=0, stop=10, num=30)\n",
    "print(arr_linspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e6118",
   "metadata": {},
   "source": [
    "### 数组基本属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53949e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数组维度\n",
    "print(arr_1_d.ndim)\n",
    "print(arr_2_d.ndim)\n",
    "\n",
    "# 数组的形状\n",
    "print(arr_1_d.shape)\n",
    "print(arr_2_d.shape)\n",
    "\n",
    "# 元素总数\n",
    "print(arr_1_d.size)\n",
    "print(arr_2_d.size)\n",
    "\n",
    "# 数组所属的数据类型\n",
    "print(arr_2_d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数组的轴\n",
    "test_axis = np.random.randint(10, size=(4,3,2))\n",
    "print(test_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582179dd",
   "metadata": {},
   "source": [
    "###  数组基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数组的操作\n",
    "print(np.sum(test_axis, axis=0))\n",
    "print(np.max(test_axis, axis=0))\n",
    "print(np.min(test_axis, axis=0))\n",
    "print(np.mean(test_axis, axis=0))\n",
    "print(np.argmin(test_axis, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4341de8f",
   "metadata": {},
   "source": [
    "## 深度学习相关操作 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c0927",
   "metadata": {},
   "source": [
    "| 函数名     | 关键功能     | 使用要点     |\n",
    "| -------- | -------- | -------- |\n",
    "| view() | 浅拷贝，用来获取与原数组共享数据的数组 | 只共享数据，无法共享形状；例如原数组1*6，新数组可以是2*3|\n",
    "| copy() | 深度拷贝 | 不共享数据，修改新数组不会影响原数组 |\n",
    "| concatenate() | 多个数组拼接 | 注意沿着哪个轴进行 |\n",
    "| argmax() | 返回具有最大值的索引 |  |\n",
    "| argsort() | 对原数组排序，返回对应的索引 |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc83d7f",
   "metadata": {},
   "source": [
    "### 图片数据加载 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27746ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('.\\source\\jikeshijian_logo.png')\n",
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78329378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "im_pillow = np.asarray(im)\n",
    "im_pillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39b903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "R、G、B三通道显示图片\n",
    "\"\"\"\n",
    "im_pillow_c1 = im_pillow[:, :, 0]\n",
    "im_pillow_c2 = im_pillow[:, :, 1]\n",
    "im_pillow_c3 = im_pillow[:, :, 2]\n",
    "\n",
    "# 二维变三维\n",
    "im_pillow_c1 = im_pillow_c1[:, :, np.newaxis]\n",
    "im_pillow_c2 = im_pillow_c2[:, :, np.newaxis]\n",
    "im_pillow_c3 = im_pillow_c3[:, :, np.newaxis]\n",
    "\n",
    "zeros = np.zeros((im_pillow.shape[0], im_pillow.shape[1], 1))\n",
    "\n",
    "im_pillow_c1_3ch = np.concatenate((im_pillow_c1, zeros, zeros), axis=2)\n",
    "im_pillow_c2_3ch = np.concatenate((zeros,im_pillow_c2, zeros), axis=2)\n",
    "im_pillow_c3_3ch = np.concatenate((zeros, zeros, im_pillow_c3), axis=2)\n",
    "\n",
    "# 绘图\n",
    "from matplotlib import pyplot as plt\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Origin Image')\n",
    "plt.imshow(im_pillow)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Red Channel')\n",
    "plt.imshow(im_pillow_c1_3ch.astype(np.uint8))\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title('Green Channel')\n",
    "plt.imshow(im_pillow_c2_3ch.astype(np.uint8))\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('Blue Channel')\n",
    "plt.imshow(im_pillow_c3_3ch.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beda46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "R、G、B三通道显示图片，方法二\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "im=Image.open('.\\source\\jikeshijian_logo.png').convert('RGB')\n",
    "print(im.size)\n",
    "print(type(im))\n",
    "im_pillow=np.array(im)\n",
    " \n",
    "im_pillow_1_3ch=np.array(im)\n",
    "im_pillow_1_3ch[:, :, 1:]=0 \n",
    "print(im_pillow_1_3ch.shape)\n",
    " \n",
    "im_pillow_2_3ch=np.array(im)\n",
    "im_pillow_2_3ch[:, :, [0,2]]=0\n",
    "print(im_pillow_2_3ch.shape)\n",
    " \n",
    "im_pillow_3_3ch=np.array(im)\n",
    "im_pillow_3_3ch[:, :, :2]=0\n",
    "print(im_pillow_3_3ch.shape)\n",
    " \n",
    "from matplotlib import pyplot as plt\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Origin Image')\n",
    "plt.imshow(im_pillow)\n",
    "plt.axis('off')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Red Channel')\n",
    "plt.imshow(im_pillow_1_3ch.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title('Green Channel')\n",
    "plt.imshow(im_pillow_2_3ch.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('Blue Channel')\n",
    "plt.imshow(im_pillow_3_3ch.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.savefig('./rgb_pillow.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650bd5f",
   "metadata": {},
   "source": [
    "### 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8cbfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array([0.075, 0.15, 0.075, 0.15, 0.0, 0.05, 0.05, 0.2, 0.25])\n",
    "# np.argsort 对原数组进行从小到大的排序，返回的是对应元素在原数组中的索引\n",
    "probs_idx_sort = np.argsort(-probs) #注意，加了负号，是按降序排序\n",
    "print(probs_idx_sort)\n",
    "print(probs_idx_sort[:3])\n",
    "max_idx = np.argmax(probs)\n",
    "print(max_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c0df6",
   "metadata": {},
   "source": [
    "# Tensor用法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36167715",
   "metadata": {},
   "source": [
    "## 创建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329a5f9",
   "metadata": {},
   "source": [
    "**直接创建**\n",
    "\n",
    "torch.tensor(data, dtype=None, device=None,requires_grad=False)\n",
    "\n",
    "data：就是要传入模型的数据。PyTorch 支持通过list、 tuple、numpy array、scalar 等多种类型进行数据传入，并转换为 tensor。\n",
    "\n",
    "dtype：它声明了你需要返回一个怎样类型的 Tensor，具体类型可以参考前面表格里列举的 Tensor 的 8 种类型。\n",
    "\n",
    "device：这个参数指定了数据要返回到的设备，目前暂时不需要关注，缺省即可。\n",
    "\n",
    "requires_grad，用于说明当前量是否需要在计算中保留对应的梯度信息。在 PyTorch 中，只有当一个 Tensor 设置 requires_grad 为 True 的情况下，才会对这个 Tensor 以及由这个 Tensor 计算出来的其他 Tensor 进行求导，然后将导数值存在Tensor 的 grad 属性中，便于优化器来更新参数。所以，你需要注意的是，把 requires_grad 设置成 true 或者 false 要灵活处理。如果是训练过程就要设置为 true，目的是方便求导、更新参数。而到了验证或者测试过程，我们的目的是检查当前模型的泛化能力，那就要把 requires_grad 设置成 Fasle，避免这个参数根据 loss 自动更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d619857",
   "metadata": {},
   "source": [
    "**从Numpy中创建**\n",
    "\n",
    "torch.from_numpy(ndarry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a15a6d",
   "metadata": {},
   "source": [
    "创建零矩阵 Tensor：零矩阵顾名思义，就是所有的元素都为 0 的矩阵。\n",
    "torch.zeros(*size, dtype=None...)\n",
    "size 定义输出张量形状的整数序列，其它参数暂时忽略\n",
    "\n",
    "创建单位矩阵 Tensor：单位矩阵是指主对角线上的元素都为 1 的矩阵\n",
    "torch.eye(size, dtype=None...)\n",
    "\n",
    "创建全一矩阵 Tensor：全一矩阵顾名思义，就是所有的元素都为 1 的矩阵\n",
    "torch.ones(size, dtype=None...)\n",
    "\n",
    "创建随机矩阵 Tensor：在 PyTorch 中有几种较为经常使用的随机矩阵创建方式，分别如下\n",
    "torch.rand(size)\n",
    "torch.randn(size)\n",
    "torch.normal(size, mean, std)\n",
    "torch.randint(low, high, size）\n",
    "\n",
    "torch.rand 用于生成数据类型为浮点型且维度指定的随机 Tensor，随机生成的浮点数据在 0~1 区间均匀分布。\n",
    "torch.randn 用于生成数据类型为浮点型且维度指定的随机 Tensor，随机生成的浮点数的取值满足均值为 0、方差为 1 的标准正态分布。\n",
    "torch.normal 用于生成数据类型为浮点型且维度指定的随机 Tensor，可以指定均值和标准差。\n",
    "torch.randint 用于生成随机整数的 Tensor，其内部填充的是在[low,high) 均匀生成的随机整数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c042fa2",
   "metadata": {},
   "source": [
    "## 转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Int 与 Tensor转换\n",
    "a = torch.Tensor(1)\n",
    "b = a.item()\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9076e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list 与 tensor 的转换\n",
    "a = [1, 2, 3]\n",
    "b = torch.Tensor(a)\n",
    "c = b.numpy().tolist()\n",
    "print(\"a:{}\".format(a))\n",
    "print(\"b:{}\".format(b))\n",
    "print(\"c:{}\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy 与 Tensor 的转换\n",
    "import numpy as np\n",
    "import torch\n",
    "a=np.array((2,2))\n",
    "b=torch.Tensor(a)\n",
    "c=np.array(b)\n",
    "print(\"a:{}\".format(a))\n",
    "print(\"b:{}\".format(b))\n",
    "print(\"c:{}\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU 与 GPU 的 Tensor 之间的转换\n",
    "CPU->GPU: data.cuda()\n",
    "GPU->CPU: data.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace76a8",
   "metadata": {},
   "source": [
    "## 常见操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c73026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取形状\n",
    "import torch\n",
    "a=torch.zeros(2, 3, 5)\n",
    "print(a.shape)\n",
    "print(a.size())\n",
    "# 元素数量\n",
    "print(a.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83864e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 矩阵转秩 (维度转换）\n",
    "\n",
    "# permute 函数可以对任意高维矩阵进行转置\n",
    "import torch\n",
    "x = torch.rand(2,3,5)\n",
    "print(\"x变换前的形状:{}\".format(x.shape))\n",
    "x = x.permute(2,1,0)\n",
    "print(\"x变换后的形状:{}\".format(x.shape))\n",
    "\n",
    "# transpose函数，不同于 permute，它每次只能转换两个维度，或者说交换两个维度的数据\n",
    "import torch\n",
    "x = torch.rand(2,3,5)\n",
    "print(\"x变换前的形状:{}\".format(x.shape))\n",
    "x = x.transpose(1,0)\n",
    "print(\"x变换后的形状:{}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cde91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形状变换\n",
    "\n",
    "# view\n",
    "import torch\n",
    "x = torch.randn(4, 4)\n",
    "print(\"x变形前的形状:{}\".format(x.shape))\n",
    "x = x.view(2,8)\n",
    "print(\"x变形后的形状:{}\".format(x.shape))\n",
    "x = x.permute(1,0)\n",
    "print(\"x维度转换后的形状:{}\".format(x.shape))\n",
    "x=x.view(4, 4)\n",
    "\n",
    "\"\"\"\n",
    "结合代码可以看到，利用 permute，我们将第 0 和第 1 维度的数据进行了变换，得到了[8, 2]形状的 Tensor，在这个新 Tensor 上进行 view 操作，忽然就报错了，为什么呢？\n",
    "\n",
    "原因一：permute会让数据不连续\n",
    "\n",
    "原因二：view 不能处理内存不连续 Tensor 的结构。\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape（可以处理不连续数据，接着上面案例写）\n",
    "# reshape 相当于进行了两步操作，先把 Tensor 在内存中捋顺了，然后再进行 view 操作。\n",
    "\n",
    "import torch\n",
    "x = torch.randn(4, 4)\n",
    "print(\"x变形前的形状:{}\".format(x.shape))\n",
    "x = x.view(2,8)\n",
    "print(\"x变形后的形状:{}\".format(x.shape))\n",
    "x = x.permute(1,0)\n",
    "print(\"x维度转换后的形状:{}\".format(x.shape))\n",
    "x=x.reshape(4, 4)\n",
    "print(\"x reshape变形后的形状:{}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增减维度（在numpy讲解中有提到过，对应的是newaxis）\n",
    "\n",
    "# squeeze()\n",
    "# 如果 dim 指定的维度的值为 1，则将该维度删除，若指定的维度值不为 1，则返回原来的 Tensor\n",
    "# 核心：这样的效果就是数据不会少，只是降维，从立体变成了平面。如果有一维他不是1个行/1个列/1个通道，从数据看就不是一个平面了，不好降维。\n",
    "\n",
    "import torch\n",
    "x = torch.rand(2,1,3)\n",
    "print(x.shape)\n",
    "y = x.squeeze(1)\n",
    "print(y.shape)\n",
    "z = y.squeeze(1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsqueeze()：这个函数主要是对数据维度进行扩充。给指定位置加上维数为 1 的维度，同样结合代码例子来看看\n",
    "import torch\n",
    "x = torch.rand(2,1,3)\n",
    "print(x.shape)\n",
    "y = x.unsqueeze(2)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d717f",
   "metadata": {},
   "source": [
    "## Tensor连接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002b502",
   "metadata": {},
   "source": [
    "在项目开发中，深度学习某一层神经元的数据可能有多个不同的来源，那么就需要将数据进行组合，这个组合的操作，我们称之为连接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cat--在已有的维度上进行连接\n",
    "cat 是 concatnate的意思，也就是拼接、联系的意思。\n",
    "第一个参数是tensors：它很好理解，就是若干个我们准备进行拼接的 Tensor。\n",
    "第二个参数是dim：指定在哪个维度上进行拼接。通俗讲假如有2个盒子，合并之后是想要改变它的宽度还是高度/厚度。\n",
    "torch.cat(tensors, dim = 0, out = None)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc58d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A=torch.ones(3,3)       # 3行3列\n",
    "B=2*torch.ones(3,3)     # 3行3列\n",
    "print(A)\n",
    "print(B)\n",
    "\n",
    "\n",
    "# 测试dim=0(0维，代表的是行的方向\n",
    "C=torch.cat((A,B),0)\n",
    "print(C.shape)\n",
    "print(C)\n",
    "\n",
    "\n",
    "# 测试dim=1（1维，代表列的方向）\n",
    "D=torch.cat((A,B),1)\n",
    "print(D.shape)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddef719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A=torch.ones(2,2,2)\n",
    "B=2*torch.ones(2,2,2)\n",
    "print(A.shape)\n",
    "print(B.shape)\n",
    "\n",
    "# 测试dim=0(0维，代表的是行的方向，盒子的高度方向)\n",
    "C=torch.cat((A,B),0)\n",
    "print(C.shape)\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "stack--增加新的维度进行连接\n",
    "torch.stack(inputs, dim=0)\n",
    "解释：inputs 表示需要拼接的 Tensor，dim 表示新建立维度的方向\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=torch.arange(0,4)\n",
    "B=torch.arange(5,9)\n",
    "print(A)\n",
    "print(B)\n",
    "\n",
    "# 测试dim=0(0维，代表的是行的方向)\n",
    "C=torch.stack((A,B),0)\n",
    "print(C)\n",
    "\n",
    "# 测试dim=1(1维，代表的是列的方向)\n",
    "D=torch.stack((A,B),1)\n",
    "print(D.shape)\n",
    "print(D)\n",
    "\n",
    "\"\"\"\n",
    "结论：从1维向量，变成2维矩阵；其实是先把向量变成矩阵再合并；不是变成了1行8列，而是4行2列。dim=x维度，潜在告诉向量数据怎么预排列。 同理对于2维变成3维。\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cb48f",
   "metadata": {},
   "source": [
    "## Tensor 切分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463717dd",
   "metadata": {},
   "source": [
    "切分操作有很多种，下面介绍其中三种类型：chunk、split、unbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "chunk --chunk 的作用就是将 Tensor 按照声明的 dim，切成几个块\n",
    "torch.chunk(input, chunks, dim=0)\n",
    "input：它表示要做 chunk 操作的 Tensor。\n",
    "chunks：它代表将要被划分的块的数量，而不是每组的数量。请注意，chunks 必须是整型。\n",
    "dim：按照哪个维度来进行 chunk。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad48021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A=torch.tensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17])\n",
    "B = torch.chunk(A, 4, 0)\n",
    "print(B)\n",
    "\n",
    "A=torch.ones(4,4)\n",
    "B = torch.chunk(A, 2, 0)\n",
    "print(B[0])\n",
    "print(B[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "split --作用就是将 Tensor 按照声明的 dim切块，预先给定每块大小\n",
    "torch.split(tensor, split_size_or_sections, dim=0)\n",
    "\n",
    "tensor：也就是待切分的 Tensor\n",
    "split_size_or_sections：当它为整数时，表示将 tensor 按照每块大小为这个整数的数值来切割；当这个参数为列表时，则表示将此 tensor 切成和列表中元素一样大小的块。\n",
    "dim：定义了要按哪个维度切分\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A=torch.rand(5,4)\n",
    "print(A)\n",
    "B=torch.split(A, 2, 0)\n",
    "print(B)\n",
    "\n",
    "A=torch.rand(5,4)\n",
    "print(A)\n",
    "B=torch.split(A,(2,3),0)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea64ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "unbind --降维切分\n",
    "torch.unbind(input, dim=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A=torch.arange(0,16).view(4,4)\n",
    "print(A)\n",
    "b=torch.unbind(A, 0)\n",
    "print(b)\n",
    "\n",
    "A=torch.arange(0,16).view(4,4)\n",
    "print(A)\n",
    "b=torch.unbind(A, 1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc835a5",
   "metadata": {},
   "source": [
    "## Tensor索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a04bc7",
   "metadata": {},
   "source": [
    "索引操作有很多方式，有提供好现成 API 的，也有用户自行定制的操作，其中最常用的两个操作就是 index_select 和 masked_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792cd4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "index_select --基于给定的索引来进行数据提取\n",
    "torch.index_select(tensor, dim, index)\n",
    "index：是 torch.Tensor 类型\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a67758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A=torch.arange(0,16).view(4,4)\n",
    "print('A',A)\n",
    "B=torch.index_select(A,0,torch.tensor([1,3]))\n",
    "print('B',B)\n",
    "C=torch.index_select(A,1,torch.tensor([0,3]))\n",
    "print('C',C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "masked_select --通过一些判断条件来进行选择\n",
    "torch.masked_select(input, mask, out=None) \n",
    "input: 表示待处理的 Tensor。\n",
    "mask: 代表掩码张量，也就是满足条件的特征掩码。这里你需要注意的是，mask 须跟 input 张量有相同数量的元素数目，但形状或维度不需要相同\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ec1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A=torch.rand(5)\n",
    "print(A)\n",
    "\n",
    "B=A>0.3\n",
    "print(B)\n",
    "\n",
    "C=torch.masked_select(A, B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=torch.rand(5)\n",
    "C=torch.masked_select(A, A>0.3)\n",
    "print('A',A)\n",
    "print('C',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68e711",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337550fd",
   "metadata": {},
   "source": [
    "Tensor 之间的连接操作：cat(已有维度)，stack(新增维度)\n",
    "\n",
    "Tensor 内部的切分操作: chunck(输入要切几块)，split(输入每块有几个元素)，unbind（降维）\n",
    "\n",
    "Tensor基于索引或者筛选条件的数据选择操作:index_select,maked_select"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nb rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
